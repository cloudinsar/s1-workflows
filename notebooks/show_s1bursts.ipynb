{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ebc92-fb8c-42d7-9d5f-6980edbf9c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import shape\n",
    "\n",
    "import folium\n",
    "from folium.plugins import Draw\n",
    "from folium.plugins.treelayercontrol import TreeLayerControl\n",
    "\n",
    "import leafmap\n",
    "\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ff8e2-f7de-4671-8cea-f723283c9880",
   "metadata": {},
   "source": [
    "## 1) Input definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640048f-132e-4506-ab84-0561a0e9fee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '2024-01-01'\n",
    "end_date = '2025-01-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2d7aa-4fb4-4fca-abf3-d66eabd6840b",
   "metadata": {},
   "source": [
    "### Define an area of interest by drawing in the map using the rectangle selection tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97db665-ceed-411a-851b-9a41defb8f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = leafmap.Map(center=(47.005, 11.507), zoom=7.5)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa674ca-8aa8-47b7-84a3-ea660210fca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat = m.draw_features\n",
    "geom_dict = feat[0]['geometry']\n",
    "geom = shape(geom_dict)\n",
    "geom.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7299ba-fdad-41cd-838f-1ccbad90c8ad",
   "metadata": {},
   "source": [
    "### Alternatively upload your area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201b1f0-09a2-4862-a443-6c3effbfffca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104ab20b-99b5-48ac-bb2b-e119433f60c9",
   "metadata": {},
   "source": [
    "## 2) Retrieve the bursts info with https request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2e886-18a5-411a-976b-6e9df8d1ee60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "https_request = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Bursts?$filter=\" + urllib.parse.quote(\n",
    "    f\"ContentDate/Start ge {start_date}T00:00:00.000Z and ContentDate/Start le {end_date}T23:59:59.000Z and \"\n",
    "    f\"PolarisationChannels eq 'VV' and \"\n",
    "    f\"OData.CSC.Intersects(area=geography'SRID=4326;{geom.wkt}')\"\n",
    ") + \"&$top=1000\"\n",
    "\n",
    "with urllib.request.urlopen(https_request) as response:\n",
    "    content = response.read().decode()\n",
    "bursts = json.loads(content)\n",
    "JSON(bursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a31fd1-081e-4c51-b510-3ce8980762d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bursts_uniqueTrack = {}\n",
    "burstId_list = []\n",
    "track_list = []\n",
    "for b in bursts['value']:\n",
    "    if b['RelativeOrbitNumber'] not in track_list:\n",
    "        bursts_uniqueTrack[b['RelativeOrbitNumber']] = {}\n",
    "        track_list.append(b['RelativeOrbitNumber'])\n",
    "    burstId_subswath = f\"BurstId: {b['BurstId']}, {b['SwathIdentifier']}\"\n",
    "    if burstId_subswath not in burstId_list:\n",
    "        bursts_uniqueTrack[b['RelativeOrbitNumber']][burstId_subswath] = b['GeoFootprint']['coordinates']\n",
    "        burstId_list.append(burstId_subswath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948dbea-0f4c-43d4-8595-3c7bace09ee1",
   "metadata": {},
   "source": [
    "## 3) Show on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b7ad9-c6a8-4621-a219-c972210beb98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the map and center it in the middle of the bursts\n",
    "lat, lon = [], []\n",
    "for burst in bursts_uniqueTrack.values():\n",
    "    for coords in burst.values():\n",
    "        lat = lat + [c[1] for c in coords[0]]\n",
    "        lon = lon + [c[0] for c in coords[0]]\n",
    "        \n",
    "m = folium.Map(\n",
    "    location=[np.mean([max(lat), min(lat)]), np.mean([max(lon), min(lon)])],\n",
    "    zoom_start=8\n",
    ")\n",
    "\n",
    "\n",
    "# Add the area of interest\n",
    "if geom.geom_type == 'Point':\n",
    "    folium.Marker([geom.y, geom.x]).add_to(m)\n",
    "\n",
    "if geom.geom_type == 'Polygon':\n",
    "    folium.Polygon(\n",
    "        locations=[(y, x) for x, y in geom.exterior.coords],\n",
    "        color='blue',\n",
    "        fill=True,            \n",
    "        fill_color='blue',    \n",
    "        fill_opacity=0.4\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "# Add each burst grouped by track\n",
    "children = []\n",
    "for track, burst in bursts_uniqueTrack.items():\n",
    "    children.append(\n",
    "        {\n",
    "            \"label\": f\"Track {track}\",\n",
    "            \"select_all_checkbox\": True,\n",
    "            \"children\": [{\"label\":str(b), \"layer\": folium.Polygon(locations=np.flip(np.squeeze(p), axis=1), color='red').add_to(m)} for b, p in burst.items()]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Show the map\n",
    "overlay_tree = {\n",
    "    \"label\": \"Burst Footprints\",\n",
    "    \"select_all_checkbox\": \"Un/select all\",\n",
    "    \"children\": children\n",
    "}\n",
    "\n",
    "TreeLayerControl(overlay_tree=overlay_tree).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13775c4a-fb02-4ecb-897c-449997b6d302",
   "metadata": {},
   "source": [
    "## 4) Plot calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4f0a9-1f92-4f5a-8aa0-2405d6c8f5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_calendar(year, month, highlighted_dates={}):\n",
    "\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "    fig, ax = plt.subplots(figsize=(4, 2))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "                \n",
    "    for row, week in enumerate(cal):\n",
    "        for col, day in enumerate(week):\n",
    "            if day == 0:\n",
    "                continue\n",
    "            color = highlighted_dates.get(day, \"white\")\n",
    "            ax.add_patch(plt.Rectangle((col - 0.5, row - 0.5), 1, 1, color=color, alpha=0.6))\n",
    "            ax.text(col, row, str(day), ha=\"center\", va=\"center\", fontsize=12, weight='bold')\n",
    "\n",
    "    ax.set_xlim(-0.5, 6.5)\n",
    "    ax.set_ylim(len(cal) - 0.5, -0.5)\n",
    "    ax.set_title(calendar.month_name[month] + f\" {year}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84393d09-9ba3-42ca-967b-90fe96381da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date, track = [], [] \n",
    "for b in bursts['value']:\n",
    "    date.append(b['BeginningDateTime'])\n",
    "    track.append(b['RelativeOrbitNumber'])\n",
    "df = pd.DataFrame(data={'date': date, 'track': track})\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df = df.drop_duplicates(subset=['track', 'year', 'month', 'day'])\n",
    "df = df.sort_values(by='date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bbd1e3-bd9a-4720-b8d3-ad04448da2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_track = {}\n",
    "fig, ax = plt.subplots(figsize=(4, len(df['track'].unique())*0.5))\n",
    "for i, t in enumerate(df['track'].unique()):\n",
    "    color_track[t] = f'C{i}'\n",
    "    ax.add_patch(plt.Rectangle((0, -i*0.5), 0.1, 0.3, color=color_track[t], alpha=0.6))\n",
    "    ax.text(0.15, -i*0.5+0.1, f'T{t}', fontsize=10)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-len(df['track'].unique())*0.5, 0.5)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "for year in df['year'].unique():\n",
    "    df_year = df.loc[df['year'] == year, :]\n",
    "    for month in df_year['month'].unique():\n",
    "        h = {}\n",
    "        for i, row in df_year.loc[df_year['month'] == month, :].iterrows():\n",
    "            h[row['day']] = color_track[row['track']]\n",
    "        display_calendar(year, month, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db48a7-95f0-464c-a078-599991c75e9c",
   "metadata": {},
   "source": [
    "## 5) Get perpendicular baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40eac3-a6d7-493b-b9f1-c4ea88df0941",
   "metadata": {},
   "source": [
    "Select one of the available sub_swath_identifier (i.e. iw1, iw2, iw3) and burstId from the following list or from the map widget above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec16b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in children:\n",
    "  print(x[\"label\"])\n",
    "  for y in x[\"children\"]:\n",
    "    print(\"  \" + y[\"label\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d52ea-ba81-48ab-9441-6d016d09752b",
   "metadata": {},
   "source": [
    "Set the required polarization, subswath identifier and correspondant burst id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292fb26-8c03-491b-95fc-3ad1b1dd7e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "track\n",
    "sub_swath_identifier = \"iw2\"\n",
    "burst_id = \"249433\"\n",
    "polarization = \"VV\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3548f5",
   "metadata": {},
   "source": [
    "Get the product names of which we need to download the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bf276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAFE_image_list = []\n",
    "S3_image_list = []\n",
    "for b in bursts['value']:\n",
    "    if b['SwathIdentifier'].lower() == sub_swath_identifier:\n",
    "        if str(b[\"BurstId\"]) == str(burst_id):\n",
    "            if b[\"ParentProductName\"] not in SAFE_image_list:\n",
    "                SAFE_image_list.append((b[\"ParentProductName\"]))\n",
    "                S3_image_list.append((b[\"S3Path\"].split(\".SAFE\")[0] + \".SAFE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6f991",
   "metadata": {},
   "source": [
    "Get the metadata from the S3 bucket (add your CDSE S3 credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfdd91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "\n",
    "if polarization.lower()==\"vv\":\n",
    "    include_pol='vv'\n",
    "    exclude_pol='vh'\n",
    "elif polarization.lower()==\"vh\":\n",
    "    include_pol='vh'\n",
    "    exclude_pol='vv'\n",
    "\n",
    "s3_endpoint = \"eodata.dataspace.copernicus.eu\"\n",
    "\n",
    "for im_safe, im_s3 in zip(SAFE_image_list,S3_image_list):\n",
    "    print(im_safe)\n",
    "    os.system(f\"s5cmd --endpoint-url \\\"https://{s3_endpoint}\\\" cp --include \\\"*{sub_swath_identifier.lower()}*\\\" --exclude \\\"*{exclude_pol}*\\\"  --exclude \\\"*.tiff\\\" --include \\\"manifest.safe\\\" \\\"s3:/\\\"{im_s3}\\\"/*\\\" {im_safe}/\")\n",
    "    os.system(f\"mkdir {im_safe}/measurement\")\n",
    "\n",
    "    command = f\"s5cmd --endpoint-url \\\"https://{s3_endpoint}\\\" -r 5 ls \\\"s3:/\\\"{im_s3}\\\"/measurement/\\\" | grep -o '\\S\\+$' | grep {include_pol} | grep {sub_swath_identifier.lower()}\"\n",
    "    result = os.popen(command).read().splitlines()\n",
    "\n",
    "    for im in result:\n",
    "        command = f\"gdal_create -ot Int8 -outsize 1 1 -bands 1 -burn 0 {im_safe}/measurement/{im}\"\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa070215",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import esa_snappy as snappy\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "\n",
    "# read products\n",
    "products = []\n",
    "for im in SAFE_image_list:\n",
    "    products.append(snappy.ProductIO.readProduct(im))\n",
    "master = products[0]\n",
    "# import the stack operator\n",
    "create_stack = snappy.jpy.get_type('eu.esa.sar.insar.gpf.coregistration.CreateStackOp')\n",
    "# create_stack = snappy.jpy.get_type('org.esa.snap.core.gpf.Operator')\n",
    "# 1st argument: list of products between which you want to compute the baseline\n",
    "# 2nd argument: a product that will receive the baselines as new metadata\n",
    "create_stack.getBaselines(products, master)\n",
    "# Now there is a new piece of metadata in product one called 'Baselines'\n",
    "baseline_root_metadata = master.getMetadataRoot().getElement('Abstracted_Metadata').getElement('Baselines')\n",
    "# You can now display all the baselines between all master/slave configurations\n",
    "master_ids = list(baseline_root_metadata.getElementNames())\n",
    "master_dates = []\n",
    "slave_dates = []\n",
    "perpendicular_baselines = []\n",
    "delta_times = []\n",
    "for master_id in master_ids:\n",
    "    slave_ids = list( baseline_root_metadata.getElement(master_id).getElementNames())\n",
    "    for slave_id in slave_ids:\n",
    "        # print(f'{master_id}, {slave_id}')\n",
    "        snap_date_mst = master_id.split(\"_\")[1]\n",
    "        date_obj_mst = parse(snap_date_mst)\n",
    "        snap_date_slv = slave_id.split(\"_\")[1]\n",
    "        date_obj_slv = parse(snap_date_slv)\n",
    "        \n",
    "        delta_time = date_obj_mst - date_obj_slv\n",
    "        # if delta_time == datetime.timedelta(0):\n",
    "            # continue\n",
    "        master_dates.append(date_obj_mst)\n",
    "        slave_dates.append(date_obj_slv)\n",
    "        delta_times.append(delta_time)\n",
    "        baseline_metadata = baseline_root_metadata.getElement(master_id).getElement(slave_id)\n",
    "        for baseline in list(baseline_metadata.getAttributeNames()):\n",
    "            if baseline == \"Perp Baseline\":\n",
    "                perpendicular_baseline = baseline_metadata.getAttributeString(baseline)\n",
    "                perpendicular_baselines.append(perpendicular_baseline)\n",
    "                print(f'{baseline}: {perpendicular_baseline}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6087e-742d-4ed5-a0e4-5d87d28d86ae",
   "metadata": {},
   "source": [
    "Create a pandas Dataframe containing all the dates combinations and the associated perpendicular and temporal baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc45bf-c4d7-44d0-b238-eb435ee5a9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[a,b,float(c),d] for a,b,c,d in zip(master_dates,slave_dates,perpendicular_baselines,delta_times)], columns=[\"master_date\",\"slave_date\",\"perp_baseline\",\"temp_baseline\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac3efa-8ed4-4b16-adb8-e5d0fba4d57c",
   "metadata": {},
   "source": [
    "Plot the perpendicular baseline wit hrespect to the master data, which can be changed with the slider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40116bc-e7bf-4f3c-8986-11990d8a6208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas  # noqa\n",
    "df.hvplot.scatter(\n",
    "    x='slave_date',\n",
    "    y='perp_baseline',\n",
    "    groupby='master_date',\n",
    "    ylim=(-500, 500),\n",
    "    rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a724fe-2063-4dc9-812d-43c0764cf66f",
   "metadata": {},
   "source": [
    "## 6) Filter data\n",
    "\n",
    "Select the maximum temporal (days) and perpendicular (meters) baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386cc83-a88b-4db4-9c7f-c4827aa95fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_reference_date = \"2024-11-01\"\n",
    "\n",
    "max_temporal_baseline = 24 # days\n",
    "max_perpendicular_baseline = 400 # meters, absolute value\n",
    "\n",
    "filter_mask = np.bitwise_and(abs(df[\"temp_baseline\"])<=datetime.timedelta(max_temporal_baseline),abs(df[\"perp_baseline\"])<=max_perpendicular_baseline)\n",
    "df_filtered = df[filter_mask].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fffd12-4d7e-47a5-85c9-83fb650b6018",
   "metadata": {},
   "source": [
    "Plot the graph showing the existing connections between date pairs after the filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b018d37-2e3b-4212-865b-bad618bab500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = df[df[\"master_date\"]==zero_reference_date].plot.scatter(\n",
    "    x='slave_date',\n",
    "    y='perp_baseline',\n",
    "    color=\"red\",\n",
    "    ylim=(-500, 500))\n",
    "for x in df_filtered.index:\n",
    "    single = df_filtered.iloc[[x]]\n",
    "    point_1 = df[np.bitwise_and(df[\"master_date\"]==zero_reference_date,np.bitwise_or(df[\"slave_date\"]==single[\"master_date\"].values[0],df[\"slave_date\"]==single[\"slave_date\"].values[0]))]\n",
    "    ax = point_1.plot.line(\n",
    "            x='slave_date',\n",
    "            y='perp_baseline',\n",
    "            legend=False,\n",
    "            ax=ax,\n",
    "            color=\"blue\",\n",
    "            linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684db5ec-a3e3-412a-bfff-2dd23add03c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create date pairs list, used as input to the SNAP workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b79db-aeb0-4b12-93b4-a2d857f6099d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reformat_date_string(date):\n",
    "    return date[:4] + date[5:7] + date[8:10]\n",
    "sbas_dates_list = [f\"{reformat_date_string(str(df_filtered.iloc[[x]]['master_date'].values[0]))}_{reformat_date_string(str(df_filtered.iloc[[x]]['slave_date'].values[0]))}\" for x in df_filtered.index]\n",
    "sbas_dates_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b50dea-9e22-4743-bb6a-9c04020419e3",
   "metadata": {},
   "source": [
    "Plot the graph showing the existing connections for a single reference date after the filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4edcda-ce5b-4ab6-af44-aae90a0d2c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_filtered_ = df[df[\"master_date\"]==zero_reference_date].reset_index()\n",
    "ax = df[df[\"master_date\"]==zero_reference_date].plot.scatter(\n",
    "    x='slave_date',\n",
    "    y='perp_baseline',\n",
    "    color=\"red\",\n",
    "    ylim=(-500, 500))\n",
    "for x in df_filtered_.index:\n",
    "    single = df_filtered_.iloc[[x]]\n",
    "    point_1 = df[np.bitwise_and(df[\"master_date\"]==zero_reference_date,np.bitwise_or(df[\"slave_date\"]==single[\"master_date\"].values[0],df[\"slave_date\"]==single[\"slave_date\"].values[0]))]\n",
    "    ax = point_1.plot.line(\n",
    "            x='slave_date',\n",
    "            y='perp_baseline',\n",
    "            legend=False,\n",
    "            ax=ax,\n",
    "            color=\"blue\",\n",
    "            linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2b250-8e2b-45c0-82db-dd3be8126b1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create date pairs list, used as input to the SNAP workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fac9e6-5bc4-4661-b89c-bfdda904b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_dates_list = [f\"{reformat_date_string(str(df_filtered_.iloc[[x]]['master_date'].values[0]))}_{reformat_date_string(str(df_filtered_.iloc[[x]]['slave_date'].values[0]))}\" for x in df_filtered_.index]\n",
    "ps_dates_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
